{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([330, 1, 128, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PklDataset(Dataset):\n",
    "    \"\"\"Get a pkled file from the folder and return\n",
    "    the formatted dataset that corresponds to it\"\"\"\n",
    "    # pylint: disable=no-member\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pkl_file (string): Path to the pkl file.\n",
    "            root_dir (string): Directory with all the data.\n",
    "        \"\"\"\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.categories = [\"arccos\",\"arccosh\",\"arcsin\",\"arcsinh\",\"arctan\",\n",
    "            \"arctan2\",\"arctanh\",\"heaviside\",\"log\",\"log10\",\"log1p\",\"log2\",\n",
    "            \"multiply\",\"sin\",\"sinh\",\"sqrt\",\"square\",\"tan\",\"tanh\",\"divide\",\n",
    "            'add', 'subtract', \"linear\",\"exponential\",\"cubic\", \"joint_normal\",\n",
    "            \"step\",\"quadratic\", \"w_shaped\", \"spiral\",\"logarithmic\",\n",
    "            \"fourth_root\", \"sin_four_pi\", \"sin_sixteen_pi\",\n",
    "            \"two_parabolas\", \"circle\", \"ellipse\", \"diamond\",\"multiplicative_noise\",\n",
    "            \"multimodal_independence\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return the total number of files in the directory.\"\"\"\n",
    "        return len(glob.glob( str(Path(self.root_dir, \"*.pkl\")) ))\n",
    "\n",
    "    def __getitem__(self, idx, img_size=128):\n",
    "        \"\"\" get the item corresponding to the index and pad the samples \n",
    "        to have img_size in both dimensions. Returns a tensor with all\n",
    "        indices concatenated\"\"\"\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        final_maps_tensor = torch.empty(size=(0,1, img_size, img_size))\n",
    "        final_labels_tensor = torch.empty(size=(0, len(self.categories)))\n",
    "\n",
    "        for index in idx:\n",
    "            with open(Path(self.root_dir, str(index)+\".pkl\"), 'rb') as file_path:\n",
    "                data_dictionary = pickle.load(file_path)\n",
    "\n",
    "            temp_map_tensor = torch.empty(size=(len(data_dictionary),1, img_size,img_size))\n",
    "            temp_labels_tensor = torch.empty(size=(len(data_dictionary), len(self.categories)))\n",
    "\n",
    "            for i, (key, entry) in enumerate(data_dictionary.items()):\n",
    "                mgc_map, _, labels = entry\n",
    "\n",
    "                # pad the datasets with wrong size\n",
    "                if any(np.array(mgc_map.shape) != img_size):\n",
    "                    num_missing = np.ones(2)*img_size - np.array(mgc_map.shape)\n",
    "\n",
    "                    # if not even add one pad in that dimension,\n",
    "                    # and then progress as if the number of\n",
    "                    #  missing was even\n",
    "                    even = np.array(num_missing%2==0)\n",
    "                    if not(all(even)):\n",
    "                        # get the numerical values\n",
    "                        odd = (~even).astype(int)\n",
    "                        padding_mask = ((0,odd[0]),\n",
    "                                        (0,odd[1]))\n",
    "                        # pad 1 time\n",
    "                        mgc_map = np.pad(mgc_map,\n",
    "                                         pad_width = padding_mask,\n",
    "                                         mode='edge')\n",
    "                        # update the number of missing\n",
    "                        num_missing = num_missing-even\n",
    "\n",
    "                    num_missing = (num_missing/2).astype(int)\n",
    "                    padding_mask = ((num_missing[0],),\n",
    "                                   (num_missing[1],))\n",
    "                    mgc_map = np.pad(mgc_map,\n",
    "                                     pad_width = padding_mask,\n",
    "                                     mode='edge')\n",
    "\n",
    "\n",
    "                # set the temporary tensors\n",
    "                temp_map_tensor[i,0, :, :] = torch.from_numpy(mgc_map).double().unsqueeze(0)\n",
    "                # get the numerical labels\n",
    "                # this works for BCELoss\n",
    "                temp_labels_tensor[i, :] = torch.from_numpy(np.isin(self.categories, labels)).double()\n",
    "\n",
    "            final_maps_tensor = torch.cat((final_maps_tensor, temp_map_tensor), dim=0)\n",
    "            final_labels_tensor = torch.cat((final_labels_tensor, temp_labels_tensor), dim=0)\n",
    "\n",
    "        return final_maps_tensor, final_labels_tensor\n",
    "\n",
    "\n",
    "root_path = Path('C:\\machine_learning\\MGC_classifier\\data')\n",
    "external_dataset = PklDataset(root_path)\n",
    "test = external_dataset[[10, 11, 12, 13]]\n",
    "test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit external_dataset[[10]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
