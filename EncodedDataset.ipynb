{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([242, 1, 128, 128]) torch.Size([242, 40])\n",
      "torch.Size([242, 1, 128, 128]) torch.Size([242, 40])\n",
      "torch.Size([251, 1, 128, 128]) torch.Size([251, 40])\n",
      "torch.Size([246, 1, 128, 128]) torch.Size([246, 40])\n",
      "torch.Size([244, 1, 128, 128]) torch.Size([244, 40])\n"
     ]
    }
   ],
   "source": [
    "class PklDataset(Dataset):\n",
    "    \"\"\"Get a pkled file from the folder and return\n",
    "    the formatted dataset that corresponds to it\"\"\"\n",
    "\n",
    "    # pylint: disable=no-member\n",
    "    # pylint: disable=too-many-locals\n",
    "    def __init__(self, root_dir):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the data.\n",
    "        \"\"\"\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.categories = [\n",
    "            \"arccos\",\n",
    "            \"arccosh\",\n",
    "            \"arcsin\",\n",
    "            \"arcsinh\",\n",
    "            \"arctan\",\n",
    "            \"arctan2\",\n",
    "            \"arctanh\",\n",
    "            \"heaviside\",\n",
    "            \"log\",\n",
    "            \"log10\",\n",
    "            \"log1p\",\n",
    "            \"log2\",\n",
    "            \"multiply\",\n",
    "            \"sin\",\n",
    "            \"sinh\",\n",
    "            \"sqrt\",\n",
    "            \"square\",\n",
    "            \"tan\",\n",
    "            \"tanh\",\n",
    "            \"divide\",\n",
    "            \"add\",\n",
    "            \"subtract\",\n",
    "            \"linear\",\n",
    "            \"exponential\",\n",
    "            \"cubic\",\n",
    "            \"joint_normal\",\n",
    "            \"step\",\n",
    "            \"quadratic\",\n",
    "            \"w_shaped\",\n",
    "            \"spiral\",\n",
    "            \"logarithmic\",\n",
    "            \"fourth_root\",\n",
    "            \"sin_four_pi\",\n",
    "            \"sin_sixteen_pi\",\n",
    "            \"two_parabolas\",\n",
    "            \"circle\",\n",
    "            \"ellipse\",\n",
    "            \"diamond\",\n",
    "            \"multiplicative_noise\",\n",
    "            \"multimodal_independence\",\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return the total number of files in the directory.\"\"\"\n",
    "        return len(glob.glob(str(Path(self.root_dir, \"*.pkl\"))))\n",
    "    \n",
    "    def __getitem__(self, idx, img_size=128):\n",
    "        \"\"\" get the item corresponding to the index and pad the samples\n",
    "        to have img_size in both dimensions. Returns a tensor with all\n",
    "        indices concatenated\"\"\"\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        final_maps_tensor = torch.empty(size=(0, 1, img_size, img_size))\n",
    "        final_labels_tensor = torch.empty(size=(0, len(self.categories)))\n",
    "\n",
    "       \n",
    "        with open(Path(self.root_dir, str(idx) + \".pkl\"), \"rb\") as file_path:\n",
    "            data_dictionary = pickle.load(file_path)\n",
    "\n",
    "        temp_map_tensor = torch.empty(\n",
    "            size=(len(data_dictionary), 1, img_size, img_size)\n",
    "        )\n",
    "        temp_labels_tensor = torch.empty(\n",
    "            size=(len(data_dictionary), len(self.categories))\n",
    "        )\n",
    "\n",
    "        for i, (_, entry) in enumerate(data_dictionary.items()):\n",
    "            mgc_map, _, labels = entry\n",
    "\n",
    "            # pad the datasets with wrong size\n",
    "            if any(np.array(mgc_map.shape) != img_size):\n",
    "                num_missing = np.ones(2) * img_size - np.array(mgc_map.shape)\n",
    "\n",
    "                # if not even add one pad in that dimension,\n",
    "                # and then progress as if the number of\n",
    "                #  missing was even\n",
    "                even = np.array(num_missing % 2 == 0)\n",
    "                if not all(even):\n",
    "                    # get the numerical values\n",
    "                    odd = (~even).astype(int)\n",
    "                    padding_mask = ((0, odd[0]), (0, odd[1]))\n",
    "                    # pad 1 time\n",
    "                    mgc_map = np.pad(mgc_map, pad_width=padding_mask, mode=\"edge\")\n",
    "                    # update the number of missing\n",
    "                    num_missing = num_missing - even\n",
    "\n",
    "                num_missing = (num_missing / 2).astype(int)\n",
    "                padding_mask = ((num_missing[0],), (num_missing[1],))\n",
    "                mgc_map = np.pad(mgc_map, pad_width=padding_mask, mode=\"edge\")\n",
    "\n",
    "            # set the temporary tensors\n",
    "            temp_map_tensor[i, 0, :, :] = (\n",
    "                torch.from_numpy(mgc_map).double().unsqueeze(0)\n",
    "            )\n",
    "            # get the numerical labels\n",
    "            # this works for BCELoss\n",
    "            temp_labels_tensor[i, :] = torch.from_numpy(\n",
    "                np.isin(self.categories, labels)\n",
    "            ).double()\n",
    "\n",
    "        final_maps_tensor = torch.cat((final_maps_tensor, temp_map_tensor), dim=0)\n",
    "        final_labels_tensor = torch.cat(\n",
    "            (final_labels_tensor, temp_labels_tensor), dim=0\n",
    "        )\n",
    "\n",
    "        return final_maps_tensor, final_labels_tensor\n",
    "    @staticmethod\n",
    "    def collate_fn(samples):\n",
    "        \"\"\"\n",
    "        redefine the collate_fn to be able to stack the arrays that are\n",
    "        randomly sized in the batch dimension\n",
    "        \"\"\"\n",
    "\n",
    "        # get the sequences\n",
    "        maps_tensors, labels_tensors = zip(*samples)\n",
    "\n",
    "        # concatenate them\n",
    "        maps_tensors_concatenated = torch.cat(maps_tensors, dim=0)\n",
    "        labels_tensors_concatenated = torch.cat(labels_tensors, dim=0)\n",
    "\n",
    "        return maps_tensors_concatenated, labels_tensors_concatenated\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root_path = Path('C:\\machine_learning\\MGC_classifier\\data')\n",
    "test_dataset = PklDataset(root_path)\n",
    "test_dlr = DataLoader(\n",
    "    dataset = test_dataset, \n",
    "    collate_fn=PklDataset.collate_fn,\n",
    "    batch_size=3\n",
    ")\n",
    "for i, test_sample in enumerate(test_dlr):\n",
    "    print(test_sample[0].shape, test_sample[1].shape)\n",
    "    if i>3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minibatch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchDataset(Dataset):\n",
    "    \"\"\"Get a set of tensors and target classes\n",
    "    a batch and return a minibatch for that batch\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return the total number of samples in the batch.\"\"\"\n",
    "        return self.data[1].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" get the correct indices\"\"\"\n",
    "        inputs, targets = self.data[0][idx, :, :, :], self.data[1][idx, :]\n",
    "        return inputs, targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\ntorch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n"
     ]
    }
   ],
   "source": [
    "minibatch_ds = MinibatchDataset(test_sample)\n",
    "dl = DataLoader(minibatch_ds, batch_size=2, shuffle=True,)\n",
    "for sample in dl:\n",
    "    print(sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# future to do\n",
    "Implement iterable dataset to be able to continuously get data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd09920ea73a556c42ddc283a2ba3948406e3884327bbb1b4cf4ffdc9661b24b6e2",
   "display_name": "Python 3.8.3 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}