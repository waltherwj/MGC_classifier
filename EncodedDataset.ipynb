{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3\n78 84\ntorch.Size([78, 1, 128, 128]) torch.Size([78, 40])\ntorch.Size([242, 1, 128, 128]) torch.Size([242, 40])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-5da780a2a87a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m )\n\u001b[1;32m--> 152\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexternal_dlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-69-5da780a2a87a>\u001b[0m in \u001b[0;36mcollate_fn\u001b[1;34m(samples)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaps_tensors_concatenated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_tensors_concatenated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "class PklDataset(Dataset):\n",
    "    \"\"\"Get a pkled file from the folder and return\n",
    "    the formatted dataset that corresponds to it\"\"\"\n",
    "\n",
    "    # pylint: disable=no-member\n",
    "    # pylint: disable=too-many-locals\n",
    "    def __init__(self, root_dir):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the data.\n",
    "        \"\"\"\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.categories = [\n",
    "            \"arccos\",\n",
    "            \"arccosh\",\n",
    "            \"arcsin\",\n",
    "            \"arcsinh\",\n",
    "            \"arctan\",\n",
    "            \"arctan2\",\n",
    "            \"arctanh\",\n",
    "            \"heaviside\",\n",
    "            \"log\",\n",
    "            \"log10\",\n",
    "            \"log1p\",\n",
    "            \"log2\",\n",
    "            \"multiply\",\n",
    "            \"sin\",\n",
    "            \"sinh\",\n",
    "            \"sqrt\",\n",
    "            \"square\",\n",
    "            \"tan\",\n",
    "            \"tanh\",\n",
    "            \"divide\",\n",
    "            \"add\",\n",
    "            \"subtract\",\n",
    "            \"linear\",\n",
    "            \"exponential\",\n",
    "            \"cubic\",\n",
    "            \"joint_normal\",\n",
    "            \"step\",\n",
    "            \"quadratic\",\n",
    "            \"w_shaped\",\n",
    "            \"spiral\",\n",
    "            \"logarithmic\",\n",
    "            \"fourth_root\",\n",
    "            \"sin_four_pi\",\n",
    "            \"sin_sixteen_pi\",\n",
    "            \"two_parabolas\",\n",
    "            \"circle\",\n",
    "            \"ellipse\",\n",
    "            \"diamond\",\n",
    "            \"multiplicative_noise\",\n",
    "            \"multimodal_independence\",\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return the total number of files in the directory.\"\"\"\n",
    "        return len(glob.glob(str(Path(self.root_dir, \"*.pkl\"))))\n",
    "    \n",
    "    def __getitem__(self, idx, img_size=128):\n",
    "        \"\"\" get the item corresponding to the index and pad the samples\n",
    "        to have img_size in both dimensions. Returns a tensor with all\n",
    "        indices concatenated\"\"\"\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        final_maps_tensor = torch.empty(size=(0, 1, img_size, img_size))\n",
    "        final_labels_tensor = torch.empty(size=(0, len(self.categories)))\n",
    "\n",
    "       \n",
    "        with open(Path(self.root_dir, str(idx) + \".pkl\"), \"rb\") as file_path:\n",
    "            data_dictionary = pickle.load(file_path)\n",
    "\n",
    "        temp_map_tensor = torch.empty(\n",
    "            size=(len(data_dictionary), 1, img_size, img_size)\n",
    "        )\n",
    "        temp_labels_tensor = torch.empty(\n",
    "            size=(len(data_dictionary), len(self.categories))\n",
    "        )\n",
    "\n",
    "        for i, (_, entry) in enumerate(data_dictionary.items()):\n",
    "            mgc_map, _, labels = entry\n",
    "\n",
    "            # pad the datasets with wrong size\n",
    "            if any(np.array(mgc_map.shape) != img_size):\n",
    "                num_missing = np.ones(2) * img_size - np.array(mgc_map.shape)\n",
    "\n",
    "                # if not even add one pad in that dimension,\n",
    "                # and then progress as if the number of\n",
    "                #  missing was even\n",
    "                even = np.array(num_missing % 2 == 0)\n",
    "                if not all(even):\n",
    "                    # get the numerical values\n",
    "                    odd = (~even).astype(int)\n",
    "                    padding_mask = ((0, odd[0]), (0, odd[1]))\n",
    "                    # pad 1 time\n",
    "                    mgc_map = np.pad(mgc_map, pad_width=padding_mask, mode=\"edge\")\n",
    "                    # update the number of missing\n",
    "                    num_missing = num_missing - even\n",
    "\n",
    "                num_missing = (num_missing / 2).astype(int)\n",
    "                padding_mask = ((num_missing[0],), (num_missing[1],))\n",
    "                mgc_map = np.pad(mgc_map, pad_width=padding_mask, mode=\"edge\")\n",
    "\n",
    "            # set the temporary tensors\n",
    "            temp_map_tensor[i, 0, :, :] = (\n",
    "                torch.from_numpy(mgc_map).double().unsqueeze(0)\n",
    "            )\n",
    "            # get the numerical labels\n",
    "            # this works for BCELoss\n",
    "            temp_labels_tensor[i, :] = torch.from_numpy(\n",
    "                np.isin(self.categories, labels)\n",
    "            ).double()\n",
    "\n",
    "        final_maps_tensor = torch.cat((final_maps_tensor, temp_map_tensor), dim=0)\n",
    "        final_labels_tensor = torch.cat(\n",
    "            (final_labels_tensor, temp_labels_tensor), dim=0\n",
    "        )\n",
    "\n",
    "        return final_maps_tensor, final_labels_tensor\n",
    "    @staticmethod\n",
    "    def collate_fn(samples):\n",
    "        \"\"\"\n",
    "        redefine the collate_fn to be able to stack the arrays that are\n",
    "        randomly sized in the batch dimension\n",
    "        \"\"\"\n",
    "\n",
    "        # get the sequences\n",
    "        maps_tensors, labels_tensors = zip(*samples)\n",
    "\n",
    "        # concatenate them\n",
    "        maps_tensors_concatenated = torch.cat(maps_tensors, dim=0)\n",
    "        labels_tensors_concatenated = torch.cat(labels_tensors, dim=0)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root_path = Path('C:\\machine_learning\\MGC_classifier\\data')\n",
    "external_dataset = PklDataset(root_path)\n",
    "external_dlr = DataLoader(\n",
    "    dataset = external_dataset, \n",
    "    collate_fn=PklDataset.collate_fn,\n",
    "    batch_size=3\n",
    ")\n",
    "for sample in external_dlr:\n",
    "    print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 79, 1, 128, 128] at entry 0 and [1, 81, 1, 128, 128] at entry 1",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-55bf4191f950>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0miterable_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchPklDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexternal_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0miterable_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable_dataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 79, 1, 128, 128] at entry 0 and [1, 81, 1, 128, 128] at entry 1"
     ]
    }
   ],
   "source": [
    "class BatchPklDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    Wrapper for the PklDataset to get specific batch sizes\n",
    "    \"\"\"\n",
    "    def __init__(self, pkl_dataset, shuffle=True):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        takes a PklDataset and initialize a 1 batch dataloader\n",
    "        \"\"\"\n",
    "        # the  dataloader\n",
    "        self.dataset=DataLoader(\n",
    "            dataset = pkl_dataset,\n",
    "            batch_size = 1,\n",
    "            shuffle = shuffle\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Run the PklDataloader until batch size is achieved\n",
    "        \"\"\"\n",
    "        for sample_batch in self.loader:\n",
    "            for \n",
    "            yield sample\n",
    "\n",
    "iterable_dataset = BatchPklDataset(external_dataset)\n",
    "iterable_dataloader = DataLoader(iterable_dataset, batch_size = 2)\n",
    "for sample in iterable_dataloader:\n",
    "    print(sample[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 2, 2] at entry 0 and [1, 2, 3] at entry 1",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-2d8e2f9c4cbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 2, 2] at entry 0 and [1, 2, 3] at entry 1"
     ]
    }
   ],
   "source": [
    "torch.stack([torch.rand([1,2,2]),torch.rand([1,2,3])], dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minibatch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchDataset(Dataset):\n",
    "    \"\"\"Get a set of tensors and target classes\n",
    "    a batch and return a minibatch for that batch\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return the total number of samples in the batch.\"\"\"\n",
    "        return self.data[1].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" get the correct indices\"\"\"\n",
    "        inputs, targets = self.data[0][idx, :, :, :], self.data[1][idx, :]\n",
    "        return inputs, targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n",
      "torch.Size([2, 1, 128, 128]) torch.Size([2, 40])\n"
     ]
    }
   ],
   "source": [
    "minibatch_ds = MinibatchDataset(test)\n",
    "dl = DataLoader(minibatch_ds, batch_size=2, shuffle=True,)\n",
    "for sample in dl:\n",
    "    print(sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# future to do\n",
    "Implement iterable dataset to be able to continuously get data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd09920ea73a556c42ddc283a2ba3948406e3884327bbb1b4cf4ffdc9661b24b6e2",
   "display_name": "Python 3.8.3 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}