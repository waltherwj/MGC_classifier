{"metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.3"}, "orig_nbformat": 2, "kernelspec": {"name": "python383jvsc74a57bd09920ea73a556c42ddc283a2ba3948406e3884327bbb1b4cf4ffdc9661b24b6e2", "display_name": "Python 3.8.3 64-bit (conda)"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["import sys\n", "from pathlib import Path\n", "\n", "import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "from torch.utils.data import random_split\n", "import matplotlib.pyplot as plt\n", "\n", "sys.path.append(\"./source/\")\n", "import mgc_classifier as mgc_classifier\n", "import dataset_loader as datasets\n"]}, {"source": ["class train_and_validate_static:\n", "    \"\"\"\n", "    class that implements training the network and\n", "    outputting validation metrics\n", "    \"\"\"\n", "\n", "    def __init__(\n", "        self, model, datapath,\n", "    ):\n", "\n", "        # initialize the model\n", "        self.model = model\n", "        self.datapath = datapath\n", "\n", "        # initialize the logging variables\n", "        self.training_loss = []\n", "        self.validation_loss = []\n", "        self.validation_accuracy = []\n", "\n", "        # training and validation datasets\n", "        self.train_ratio = 0.8\n", "        self.train_data = None\n", "        self.validation_data = None\n", "\n", "    def train(self, epochs=1):\n", "        \"\"\"\n", "        train the network\n", "        \"\"\"\n", "\n", "        # get the full dataset in the folder\n", "        folder_dataset = datasets.PklDataset(self.datapath)\n", "\n", "        # split data into training and test\n", "\n", "        self.train_data, self.validation_data = random_split(\n", "            dataset=folder_dataset,\n", "            lengths=[\n", "                int(len(folder_dataset) * self.train_ratio),\n", "                len(folder_dataset) - int(len(folder_dataset) * self.train_ratio),\n", "            ],\n", "        )\n", "\n", "        # iterate through the epochs\n", "        for epoch in range(epochs):\n", "            print(epoch)\n", "\n", "    def validate(self):\n", "        \"\"\"\n", "        validate the network predictions\n", "        \"\"\"\n", "\n", "\n", "test_model = mgc_classifier.MgcNet(\n", "    out_channels=10, num_conv_layers=3, n_classes=10, img_size=32\n", ")\n", "root_path = Path(\"C:\\machine_learning\\MGC_classifier\\data\")\n", "train_val_object = train_and_validate_static(test_model, root_path)\n", "train_val_object.train()\n"], "cell_type": "code", "metadata": {}, "execution_count": 17, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["0\n"]}]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}]}