{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from scipy.stats import multiscale_graphcorr as MGC\n",
    "import scipy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from inspect import getmembers\n",
    "import inspect\n",
    "import warnings\n",
    "import hyppo\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1019, 0.1007, 0.0994, 0.1025, 0.0976, 0.0985, 0.1015, 0.0987, 0.0979,\n",
       "         0.1013]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MgcNet(nn.Module):\n",
    "    \"\"\" take an MGC correlation map and predict\n",
    "    the operations that could have taken to that\n",
    "    map\"\"\"\n",
    "    # pylint: disable=too-many-instance-attributes\n",
    "    # pylint: disable=too-many-arguments\n",
    "    def __init__(self, out_channels, num_conv_layers, n_classes, kernel=3, img_size=128):\n",
    "        super().__init__()\n",
    "\n",
    "        # initialize some values\n",
    "        self.out_channels = out_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.img_size = img_size\n",
    "        self.num_conv_layers=num_conv_layers\n",
    "\n",
    "        # get the padding for same padding. Assumes stride=1\n",
    "        pad = int(np.ceil((kernel-1)/2))\n",
    "\n",
    "        ####################################################\n",
    "        # layers\n",
    "        # convolutional layers\n",
    "        self.conv_input = nn.Conv2d(in_channels = 1,\n",
    "                               out_channels = out_channels,\n",
    "                               kernel_size = kernel,\n",
    "                               padding = pad)\n",
    "        self.successive_poolings = 0\n",
    "        # account for the input convolutional layer too (-1)\n",
    "        for i in range(num_conv_layers-1):\n",
    "            setattr(self, 'conv'+str(i), nn.Conv2d(in_channels = out_channels,\n",
    "                               out_channels = out_channels,\n",
    "                               kernel_size = kernel,\n",
    "                               padding = 1))\n",
    "            if img_size//(2**self.successive_poolings)>32:\n",
    "                setattr(self, 'maxpool'+str(i),nn.MaxPool2d(kernel_size = 3,\n",
    "                                         stride = 2,\n",
    "                                         padding=1))\n",
    "                self.successive_poolings+=1\n",
    "            else:\n",
    "                setattr(self, 'maxpool'+str(i),nn.MaxPool2d(kernel_size = 3,\n",
    "                                         stride = 1,\n",
    "                                         padding=1))\n",
    "        pooled_output_size = img_size//(2**self.successive_poolings)\n",
    "\n",
    "        # linear layers\n",
    "        in_features_linear = out_channels * pooled_output_size * pooled_output_size\n",
    "        transition_features_linear = (n_classes +\n",
    "                        (out_channels * pooled_output_size * pooled_output_size)//2)\n",
    "        setattr(self, 'linear'+str(0), nn.Linear(in_features = in_features_linear,\n",
    "                                            out_features = transition_features_linear))\n",
    "        setattr(self, 'linear'+str(1), nn.Linear(in_features = transition_features_linear,\n",
    "                                            out_features = n_classes))\n",
    "\n",
    "        # activation layers\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.define_sequence()\n",
    "\n",
    "    def define_sequence(self):\n",
    "        \"set sequence to make it easier for the forward pass\"\n",
    "        self.sequence = []\n",
    "        n_appended_convs = 0\n",
    "\n",
    "        for name, seq_module in self.named_modules():\n",
    "            number=[]\n",
    "\n",
    "            # set convolutional step\n",
    "            if isinstance(seq_module, nn.Conv2d):\n",
    "                n_appended_convs+=1\n",
    "                self.sequence.append(seq_module)\n",
    "                self.sequence.append(self.relu)\n",
    "                number = re.findall(r'\\d+', name)\n",
    "\n",
    "            # check if list is not empty to set the maxpool layers\n",
    "            if (len(number) > 0) and 'conv' in name:\n",
    "                #find the maxpool with corresponding number\n",
    "                for maxpool_name, maxp_module in self.named_modules():\n",
    "                    maxpool_number =  re.findall(r'\\d+', maxpool_name)\n",
    "                    if isinstance(maxp_module, nn.MaxPool2d) and maxpool_number == number:\n",
    "                        self.sequence.append(maxp_module)\n",
    "\n",
    "            # set the linear steps\n",
    "            if isinstance(seq_module, nn.Linear) and n_appended_convs==self.num_conv_layers:\n",
    "                self.sequence.append(seq_module)\n",
    "                self.sequence.append(self.relu)\n",
    "\n",
    "        #remove the last relu and change to softmax\n",
    "        self.sequence.pop(-1)\n",
    "        self.sequence.append(self.softmax)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"forward pass of the MGC classifier\"\n",
    "\n",
    "        # control changing x to a view or not\n",
    "        first_linear = True\n",
    "\n",
    "        # iterate through the layers\n",
    "        for layer in self.sequence:\n",
    "            # if the first linear layer, change tensor to be in the correct shape\n",
    "\n",
    "            if isinstance(layer, nn.Linear) and first_linear:\n",
    "                pooled_output_size = self.img_size//(2**self.successive_poolings)\n",
    "                tensor = tensor.view(-1,\n",
    "                            self.out_channels * pooled_output_size * pooled_output_size)\n",
    "                first_linear = False\n",
    "\n",
    "            # apply the layer\n",
    "            tensor = layer(tensor)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "        \n",
    "model_test = MGC_NET(out_channels = 10, \n",
    "        num_conv_layers = 3, \n",
    "        n_classes = 10,\n",
    "        img_size=32)\n",
    "\n",
    "dummy_data = torch.rand(size=[1,1, 32, 32])\n",
    "\n",
    "model_test.forward(dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGC_NET(\n",
      "  (conv_input): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  (linear2): Linear(in_features=5125, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'conv_layers1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-132060fe87b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'conv_layers'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'conv_layers1'"
     ]
    }
   ],
   "source": [
    "getattr(nn, 'conv_layers'+str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MGC_adversary():\n",
    "    \"\"\" gets results from network and adjust the\n",
    "    probabilities so that the classifier performs \n",
    "    worse\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
